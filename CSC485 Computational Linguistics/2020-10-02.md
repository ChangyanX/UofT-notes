# 2020-10-02

* Systematic polysemy
  * Applies to most or all senses of certain semantic classes
* Relation between senses
  * Hyponynmy, hyperonymy: subtype and supertype
    * sedan is a hyponym of car
    * car is a hyperonym of sedan
  * Fundamental relation for creating a taxonomy: tree like structure that expresses classes and inheritence of properties
* Meronymy, holonymy: part/whole, or membership
  * leg is a meronym of chair
  * chair is a holonym of leg, and a meronym of a dining set
* subtypes of meronym relations
  * Component-of: Kitchen is a component of apartment
  * Member-of: Soldier, army
  * Portion-of: Slice, pie
* Entailment, implicature
  * snore entails sleep
  * manage implies try
  * we end up getting a whole lot of entailment relations
  * rely on world knowledge, we need to know something about processes.
* How do we get a lexicon with these relations?
  * Dictionary? 
    * Not all dictionaries are as good.
    * Learner's dictionaries have definitions but also examples!
    * Extraction from online dictionary?
  * Corpora?
    * Bias of corpus?
    * Sheer size will hide mistakes
    * May use words differently and incorrectly
    * Corpus based pattern recognition
  * Built by hand?
  * WordNet: hierachical taxonomic lexicon and theaurus of English
    * Lexicographers at Princeton in the 1990s
    * Graph structure: nodes are synsets (synonym sets) that approximate word senses.  
    * Chopping up words into individual senses
    * example: `slip`
      * `slip#1` (a socially awkward or tactless act)
        * `gaucherie#2`, `faux pas#1`, `gaffe#1`, `solecism#`
      * `slip#2`, (a minor inadvertent mistake usually observed in speech or writing or in small accidents or memory lapses)
        * `slip-up#1`, `miscue#2`
      * `slip#3`, (potters clay that is thinned and used for coating or decorating ceramics)
      * ... and so on and so forth
    * Treat word senses as a network, relative to their neighbouring nodes.
    * Entity relation is like the organism concept of taxonomical drawings in Biology
      * Lots of entity are objects, substances
      * Leaf node: no known hyponyms for a word
      * hyponomy is not a graphical representation
        * a "bad" word only means one single thing :: hyponym
        * somehow entity does always end up at the top
      * If we assign probabilities to an entity relation we might be able to typify the meaning of a word in a corpus
        * Edges from hyponymy: near-tree
        * Edges from meronymy: network
      * Index maps each word to all of its synsets
      * We have separate trees for nouns, verbs
        * With devrivational cross connections, for example N destruction would link to V to destroy.
      * Hyponyms of a node are differentiations of its meaning
    * Wordnets available in other languages
    * Need a complete lexicon and lexical relation for each natlang
      * Can we use another WordNet as a starting point?
* In 2004 Gerald Penn found a cycle in WordNet :)
* "group" 
* Hearst: Automated discover of WordNet relations
  * Corpus based method that makes suggestions for lexicographes
  * We look at partially parsed text for instances of paterns
    * such \(NP_1\) as \(\{NP_i\}* \{or|and\} NP_i \implies NP_1\) is a hyperonym of \(NP_i\)
      * chunking, "grep-like"
    * Search text of Y and Z/Y or Z.
    * Give us an instance of NP1
    * "special characters **such as** dingbats and accented"
    * "aggregate documents **such as** html"
  * We develop patterns by hand, or scanning sentences containing known related pairs.
  * We can learn a lot of WordNet through these patterns
    * fabric-silk, grain-barley, disorders-epilepsy
    * Some are not in WN
      * crops-milo, perishibles-fruit, conditions-epilepsy
    * Some relations with words not yet in WordNet
      * companies-Shell, institutions-Tufts
    * Some too general
      * things-excercise, topics-nutrition, areas-Sacremental
    * Some too context specific
      * others-Meadowbrook, classics-Gaslight, categories-drama
    * Some really bad relations
      * children-Headstart, jobs-computer, companies-sports
  * Problems: which word is the hyperonym?
    * A *bearing* is a *structure* that supports a *rotating part of the machine* **such as** a shaft, axle, spindle, or a wheel.
      * What is the \(NP_1\) here?
      * How can we quantitively evaulate
      * Does not work with meronyms. We don't have good patterns for meronyms.
* Since Hearst's paper we have some syntactic patterns that derive patterns from corpora
* Methods that use senses, not words
* Methods that combine evidence to identify additional relations
  * Sister(X, Y) and Hyponym(Y, Z) => Hyponym(X, Z)