# 2019-09-30

* fsck checks superblocks, traverse all inodes, etc.
  * only FS integrity, can't do anything about lost data
  * The bigger our disk is the slower fsck is.

## Journaling
* Write-ahead-logging
* When we do an update before overwriting a structure, we log the operation.
* If a crash happens, we only look at operations that haven't been completed.
* Don't need to scan entire disk
* We can possibly recover data
* ext3 extends ext2 with log
* Can be though though of a transction

```c
typedef struct journal {
    txbegin_t TxBegin; // magic number
    inode_t inode;
    bitmap_t bitmap;
    datablock_t datablock;
    txend_t TxEnd;
} journal_t;
```

Store the inodes, bitmap, and datablock to write, then mark as ended.

If power cuts off before TxEnd is written, then it looks like an invalid transaction.

What happens when disk loses power before Db is written, but TxEnd is written already from internal disk scheduling.

We do this by writing all except TxEnd to tje journal. Once the journal completes, we write txEnd. Now journal is complete, we can mark tx as free.

If crash happens before transaction is commited, we can skip. If power is cut off, we can replay.

Normal operations are slower, but recovery is much faster because we need to write to journal first then the update.

Metadata journaling is when we only write the fs metadata.

Journaling
  * ensures fs consistency
  * complexity is size of the journal, not size of the disk
  * is fsck useless
  * metadata journaling is most commonly used
    * reduces the amount of traffic to the journal and get reasonable consistency
  * widely adopted in most modern fs

How journaling came to be?
* LFS
Crashes assume disks are still usable after rebooting.
* RAID
  * Redundant array of ~~inexpensive~~ independent disks
  * Duplicate data
  * spread data across multiple disks
  * parity: xor each bit from 2 drives, store chcksum on 3rd
  * multiple RAID levels
* RAID0
  * No redundancy
  * improves throughput
  * if one drive is lost, whole volume is lost
* RAID1
  * Mirroring
  * capacity is half
  * any drive and serve a read, so improved rea
* RAID5
 * block level striping
 * distributed parity
 * failed disk can be reconstructed