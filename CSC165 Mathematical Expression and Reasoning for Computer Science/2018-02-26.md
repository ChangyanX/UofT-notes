# 2018-02-26

> **Definition**. We say that of two functions \(f\) and \(g\), that \(g\) is *eventually dominated* by \(f\) if and only if \(\exists n_0 \in \mathbb{N}. \forall n \in \mathbb{N}. n \geq n_0 \Rightarrow g(n) \leq f(n)\).

> **Definition**. We say that of two functions \(f\) and \(g\), that \(g\) is *eventually dominated up to a constant* by \(f\) if and only if  \(\exists c, n_0 \in \mathbb{R^+}. \forall n \in \mathbb{N}. n \geq n_0 \Rightarrow g(n) \leq c f(n)\).

Hence we lead into the formal definition of Big-O notation. 

> **Definition**. If \(g\) is eventually dominated up to a constant by \(f\), then we write \(g \in O(f)\).

\(O(f)\) is the set of functions that grow slower than some function \(f\).


> **Claim.** All linear functions are dominated by some other linear function up to a constant. Formally, \(\forall a, b \in \mathbb{R^+} an + b \in O(n)\). In other words, all linear functions grow the same. 

> **Proof.** We want to show that \(\exists c, n_0 \in \mathbb{R^+}. \forall n \in \mathbb{N}. n \geq n_0 \Rightarrow an+b \leq cn\). 
> 
> Let \(a, b \in  \mathbb{R^+}\). Let \(c = a + 1\) and \(n_0 = \frac{b}{c-a}\). 

\(f \in O(g)\) notation simply means that \(g\) is an upper bound of f.

There are other notations which we will use, such as \(\Theta\) and \(\Omega\)
They are defined as follows:

\(f \in \Omega(g) \Leftrightarrow g \in O(f)\), or in English, \(g\) is a lower bound of \(f\) is a lower bound of \(f\) asymptotically.

Notice that \(\Theta\) has a bar in the middle, representing that \(g\) bounds \(f\), and \(\Omega\) has a bar on the bottom, representing that \(g\) is a lower bound. Generally \(O\) is written \(\mathcal{O}\) with a bar on top, representing that \(g\) is a upper bound.

\(f \in \Theta(g) \Leftrightarrow f \in O(g)  \cap \Omega (g)\), or in English, \(g\) is an upper and a lower bound of \(f\) asymptotically.
